{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d25e2c6",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "da99532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "# Modelling\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor,GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, Ridge,Lasso\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ae4001af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race_ethnicity</th>\n",
       "      <th>parental_level_of_education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test_preparation_course</th>\n",
       "      <th>math_score</th>\n",
       "      <th>reading_score</th>\n",
       "      <th>writing_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>69</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>group A</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender race_ethnicity parental_level_of_education         lunch  \\\n",
       "0  female        group B           bachelor's degree      standard   \n",
       "1  female        group C                some college      standard   \n",
       "2  female        group B             master's degree      standard   \n",
       "3    male        group A          associate's degree  free/reduced   \n",
       "4    male        group C                some college      standard   \n",
       "\n",
       "  test_preparation_course  math_score  reading_score  writing_score  \n",
       "0                    none          72             72             74  \n",
       "1               completed          69             90             88  \n",
       "2                    none          90             95             93  \n",
       "3                    none          47             57             44  \n",
       "4                    none          76             78             75  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/stud.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a9f7db",
   "metadata": {},
   "source": [
    "## Preparing X & y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bedeece3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns= 'math_score')\n",
    "X.head()\n",
    "print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8c59ca74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    72\n",
       "1    69\n",
       "2    90\n",
       "3    47\n",
       "4    76\n",
       "Name: math_score, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['math_score']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4a389e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories in 'gender' variable:      ['female' 'male']\n",
      "Categories in 'race_ethnicity' variable:   ['group B' 'group C' 'group A' 'group D' 'group E']\n",
      "Categories in'parental level of education' variable: [\"bachelor's degree\" 'some college' \"master's degree\" \"associate's degree\"\n",
      " 'high school' 'some high school']\n",
      "Categories in 'lunch' variable:      ['standard' 'free/reduced']\n",
      "Categories in 'test preparation course' variable:      ['none' 'completed']\n"
     ]
    }
   ],
   "source": [
    "print(\"Categories in 'gender' variable:     \",end=\" \" )\n",
    "print(df['gender'].unique())\n",
    "\n",
    "print(\"Categories in 'race_ethnicity' variable:  \",end=\" \")\n",
    "print(df['race_ethnicity'].unique())\n",
    "\n",
    "print(\"Categories in'parental level of education' variable:\",end=\" \" )\n",
    "print(df['parental_level_of_education'].unique())\n",
    "\n",
    "print(\"Categories in 'lunch' variable:     \",end=\" \" )\n",
    "print(df['lunch'].unique())\n",
    "\n",
    "print(\"Categories in 'test preparation course' variable:     \",end=\" \" )\n",
    "print(df['test_preparation_course'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d2b26b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a column transformer with 3 types of transformer\n",
    "num_features = X.select_dtypes(exclude= 'object').columns\n",
    "onehot_column = X.select_dtypes(include='object').columns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "oh_transformer = OneHotEncoder(drop= 'first')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"OneHotEncoder\",oh_transformer,onehot_column),\n",
    "        (\"StandardScaler\", numeric_transformer,num_features)\n",
    "    ], remainder= 'passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "aed132ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.193999</td>\n",
       "      <td>0.391492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.427476</td>\n",
       "      <td>1.313269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.770109</td>\n",
       "      <td>1.642475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.833899</td>\n",
       "      <td>-1.583744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.605158</td>\n",
       "      <td>0.457333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.044215</td>\n",
       "      <td>1.774157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.970952</td>\n",
       "      <td>-0.859491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125472</td>\n",
       "      <td>-0.201079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.605158</td>\n",
       "      <td>0.589015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.153370</td>\n",
       "      <td>1.181586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7    8    9    10   11        12  \\\n",
       "0    0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  1.0  0.193999   \n",
       "1    0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  1.427476   \n",
       "2    0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  1.0  1.770109   \n",
       "3    1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0 -0.833899   \n",
       "4    1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  1.0  0.605158   \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...   \n",
       "995  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  2.044215   \n",
       "996  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0 -0.970952   \n",
       "997  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.125472   \n",
       "998  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.605158   \n",
       "999  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  1.153370   \n",
       "\n",
       "           13  \n",
       "0    0.391492  \n",
       "1    1.313269  \n",
       "2    1.642475  \n",
       "3   -1.583744  \n",
       "4    0.457333  \n",
       "..        ...  \n",
       "995  1.774157  \n",
       "996 -0.859491  \n",
       "997 -0.201079  \n",
       "998  0.589015  \n",
       "999  1.181586  \n",
       "\n",
       "[1000 rows x 14 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = preprocessor.fit_transform(X)\n",
    "pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a8f4299f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 14)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4ab37a",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5d5cfa0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 14), (200, 14))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size= 0.2, random_state= 42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9a6b56",
   "metadata": {},
   "source": [
    "## Model training and model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b45f9c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Create a function to evaluate model\n",
    "\n",
    "def evaluate_model(true,predicted):\n",
    "    mae = mean_absolute_error(true,predicted)\n",
    "    mse = mean_squared_error(true,predicted)\n",
    "    rmse = np.sqrt(mse)\n",
    "    R2_score = r2_score(true,predicted)\n",
    "    return mae,rmse,R2_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4eae0c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 5.3231\n",
      "- Mean Absolute Error: 4.2667\n",
      "- R2 Score: 0.8743\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 5.3940\n",
      "- Mean Absolute Error: 4.2148\n",
      "- R2 Score: 0.8804\n",
      "===================================\n",
      "\n",
      "\n",
      "Lasso\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 6.5938\n",
      "- Mean Absolute Error: 5.2063\n",
      "- R2 Score: 0.8071\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 6.5197\n",
      "- Mean Absolute Error: 5.1579\n",
      "- R2 Score: 0.8253\n",
      "===================================\n",
      "\n",
      "\n",
      "Ridge\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 5.3235\n",
      "- Mean Absolute Error: 4.2650\n",
      "- R2 Score: 0.8743\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 5.3936\n",
      "- Mean Absolute Error: 4.2125\n",
      "- R2 Score: 0.8805\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Regression\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 5.5678\n",
      "- Mean Absolute Error: 4.4510\n",
      "- R2 Score: 0.8625\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 7.3774\n",
      "- Mean Absolute Error: 5.7110\n",
      "- R2 Score: 0.7763\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 0.2795\n",
      "- Mean Absolute Error: 0.0187\n",
      "- R2 Score: 0.9997\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 8.0034\n",
      "- Mean Absolute Error: 6.4350\n",
      "- R2 Score: 0.7368\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 2.3061\n",
      "- Mean Absolute Error: 1.8352\n",
      "- R2 Score: 0.9764\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 5.9919\n",
      "- Mean Absolute Error: 4.6920\n",
      "- R2 Score: 0.8525\n",
      "===================================\n",
      "\n",
      "\n",
      "Adaboost Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 5.7371\n",
      "- Mean Absolute Error: 4.6950\n",
      "- R2 Score: 0.8540\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 5.9534\n",
      "- Mean Absolute Error: 4.6647\n",
      "- R2 Score: 0.8543\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boost Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 4.6772\n",
      "- Mean Absolute Error: 3.7521\n",
      "- R2 Score: 0.9030\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 5.5619\n",
      "- Mean Absolute Error: 4.2975\n",
      "- R2 Score: 0.8729\n",
      "===================================\n",
      "\n",
      "\n",
      "Xgboost Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 1.0509\n",
      "- Mean Absolute Error: 0.7101\n",
      "- R2 Score: 0.9951\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 6.5248\n",
      "- Mean Absolute Error: 5.0785\n",
      "- R2 Score: 0.8250\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "                \"LinearRegression\" : LinearRegression(),\n",
    "                \"Lasso\" : Lasso(),\n",
    "                \"Ridge\": Ridge(),\n",
    "                \"K-Neighbors Regression\": KNeighborsRegressor(),\n",
    "                \"Decision Tree\": DecisionTreeRegressor(),\n",
    "                \"Random Forest Regressor\": RandomForestRegressor(),\n",
    "                \"Adaboost Regressor\": AdaBoostRegressor(),\n",
    "                \"Gradient Boost Regressor\": GradientBoostingRegressor(),\n",
    "                \"Xgboost Regressor\": XGBRegressor()\n",
    "    }\n",
    "\n",
    "model_list = []\n",
    "r2_list =[]\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "        model = list(models.values())[i]\n",
    "        model.fit(X_train, y_train)  ## Train the model\n",
    "\n",
    "        ##make Predictions\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        ##Evaluate train and test dataset\n",
    "\n",
    "        model_train_mae, model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
    "        model_test_mae, model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "        \n",
    "        print(list(models.keys())[i])\n",
    "        model_list.append(list(models.keys())[i])\n",
    "\n",
    "        print('Model performance for Training set')\n",
    "        print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "        print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "        print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "    \n",
    "        print('----------------------------------')\n",
    "        \n",
    "        print('Model performance for Test set')\n",
    "        print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "        print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "        print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "        r2_list.append(model_test_r2)\n",
    "\n",
    "        print('='*35)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a285ab38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>R2_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.880451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.880433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gradient Boost Regressor</td>\n",
       "      <td>0.872874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adaboost Regressor</td>\n",
       "      <td>0.854346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest Regressor</td>\n",
       "      <td>0.852459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.825320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Xgboost Regressor</td>\n",
       "      <td>0.825046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K-Neighbors Regression</td>\n",
       "      <td>0.776335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.736766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model Name  R2_Score\n",
       "2                     Ridge  0.880451\n",
       "0          LinearRegression  0.880433\n",
       "7  Gradient Boost Regressor  0.872874\n",
       "6        Adaboost Regressor  0.854346\n",
       "5   Random Forest Regressor  0.852459\n",
       "1                     Lasso  0.825320\n",
       "8         Xgboost Regressor  0.825046\n",
       "3    K-Neighbors Regression  0.776335\n",
       "4             Decision Tree  0.736766"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(zip(model_list, r2_list)), columns=['Model Name', 'R2_Score']).sort_values(by=[\"R2_Score\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8b638416",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Performing Hyperparameter Tuning for Ridge, Linear Regression and Gradient Boosting\n",
    "\n",
    "###initialize few params for Ridge, Gradient Boost\n",
    "\n",
    "ridge_params = {'alpha': [1,3,5,7,10],\n",
    "                'fit_intercept' : [True],\n",
    "                'max_iter' : [1000,2000,3000,5000,7000,9000,11000,15000],\n",
    "                'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga', 'lbfgs']}\n",
    "                \n",
    "\n",
    "gboost_params = {'loss': ['squared_error', 'absolute_error', 'huber', 'quantile'],\n",
    "                 'learning_rate': [0.1,0.3,0.5,0.7,0.9,1],\n",
    "                 'n_estimators' : [100,300,500,700,900,1000,1300,1500],\n",
    "                 'criterion': ['friedman_mse','squared_error'],\n",
    "                 'min_samples_split': [2,5,7,9,11,13,15,17,20],\n",
    "                 'min_samples_leaf': [1,3,5,7,9,11,13,15,17,19],\n",
    "                 'min_weight_fraction_leaf': [0.1,0.01,0.0001,0.2,0.002,0.004,0.4,0.5],\n",
    "                 'max_depth': [3,5,7,9,11,13,15],\n",
    "                 'random_state': [42,'None']\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4792075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Models list for Hyperparameter tuning\n",
    "randomcv_models = [\n",
    "                   ('ridge',Ridge(),ridge_params),\n",
    "                    ('gradientboost',GradientBoostingRegressor(),gboost_params)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2310c297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\project\\mlproject\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "30 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\project\\mlproject\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\project\\mlproject\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"e:\\project\\mlproject\\venv\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 1131, in fit\n",
      "    return super().fit(X, y, sample_weight=sample_weight)\n",
      "  File \"e:\\project\\mlproject\\venv\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py\", line 808, in fit\n",
      "    raise ValueError(\n",
      "ValueError: 'lbfgs' solver can be used only when positive=True. Please use another solver.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "e:\\project\\mlproject\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.8643919  0.86635434 0.8643919         nan 0.86439562 0.86648985\n",
      "        nan 0.86649797 0.86635235 0.86597389 0.86439367        nan\n",
      " 0.86649913 0.86635817 0.86542542 0.86542606 0.86597389 0.86542606\n",
      " 0.86649365 0.86635434 0.86597389        nan 0.86649797 0.86649931\n",
      " 0.86542606 0.86635831 0.86542606 0.86541987 0.86649797 0.86649772\n",
      " 0.86439178 0.86542606 0.86542606 0.86439562 0.86597404 0.86542917\n",
      " 0.86635831 0.86636142        nan 0.86649861 0.86439562 0.86636007\n",
      " 0.86542598 0.86439178 0.86649894 0.86635831 0.8643919  0.86597503\n",
      " 0.86648985 0.8654254  0.86542332 0.86635831 0.86596513 0.8643919\n",
      " 0.86596513 0.86650001 0.86597009 0.86542332 0.86649865 0.86636065\n",
      " 0.86541987        nan 0.86597519 0.86597389 0.86542681 0.86635733\n",
      " 0.86597519 0.86649645 0.86597344 0.86635235 0.86596513 0.86648985\n",
      " 0.86648985 0.86597389 0.86649891 0.86542606 0.86597389 0.86635831\n",
      " 0.86542606 0.86597446        nan 0.86542606 0.86597375 0.865976\n",
      " 0.86635664 0.86542606 0.86439562        nan 0.86649797 0.86635831\n",
      " 0.86542412        nan        nan 0.86635434 0.86439562 0.86649365\n",
      " 0.86649797 0.86597389 0.86635831 0.86542606]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\project\\mlproject\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "162 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "162 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\project\\mlproject\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\project\\mlproject\\venv\\lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"e:\\project\\mlproject\\venv\\lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"e:\\project\\mlproject\\venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 96, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'random_state' parameter of GradientBoostingRegressor must be an int in the range [0, 4294967295], an instance of 'numpy.random.mtrand.RandomState' or None. Got 'None' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "e:\\project\\mlproject\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan  0.77642904  0.70926273  0.45265887\n",
      "  0.62831939         nan -0.00271714         nan         nan         nan\n",
      "         nan         nan -0.00271714  0.73869902         nan         nan\n",
      "         nan  0.75529909         nan  0.62538009         nan         nan\n",
      "         nan  0.62340303         nan  0.6236726   0.80147587  0.6380878\n",
      "         nan  0.76632294         nan         nan         nan  0.76672722\n",
      "         nan         nan  0.8142676   0.80210661         nan         nan\n",
      "  0.78101683  0.77987586         nan         nan         nan         nan\n",
      "         nan         nan -0.00271714         nan         nan         nan\n",
      "  0.62827779  0.83014057         nan         nan         nan  0.02508642\n",
      "  0.79841257         nan  0.803764   -1.80644936         nan  0.78914682\n",
      "         nan         nan  0.77769087  0.75867019  0.78698932  0.53722442\n",
      "  0.81207241  0.74174427  0.71236842  0.55638665         nan         nan\n",
      "         nan  0.72615786         nan  0.61699136  0.77114136  0.78389245\n",
      "         nan  0.79384284         nan  0.62835803  0.75978467         nan\n",
      "  0.79437743         nan         nan  0.62827779  0.8076353          nan\n",
      "  0.68449126         nan         nan         nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Best Params for ridge-----------------------\n",
      "{'solver': 'saga', 'max_iter': 9000, 'fit_intercept': True, 'alpha': 1}\n",
      "--------------------Best Params for gradientboost-----------------------\n",
      "{'random_state': 42, 'n_estimators': 100, 'min_weight_fraction_leaf': 0.01, 'min_samples_split': 13, 'min_samples_leaf': 13, 'max_depth': 13, 'loss': 'absolute_error', 'learning_rate': 0.1, 'criterion': 'friedman_mse'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "model_param = {}\n",
    "for name,model,params in randomcv_models:\n",
    "    random = RandomizedSearchCV(estimator= model,\n",
    "                               param_distributions=params,\n",
    "                               n_iter=100,\n",
    "                               cv=3,\n",
    "                               verbose=2,\n",
    "                               n_jobs=-1)\n",
    "    random.fit(X_train,y_train)\n",
    "    model_param[name]= random.best_params_\n",
    "\n",
    "for model_name in model_param:\n",
    "    print(f\"--------------------Best Params for {model_name}-----------------------\")\n",
    "    print(model_param[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "24967df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 5.3235\n",
      "- Mean Absolute Error: 4.2650\n",
      "- R2 Score: 0.8743\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 5.3937\n",
      "- Mean Absolute Error: 4.2126\n",
      "- R2 Score: 0.8804\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boost Regressor\n",
      "Model performance for Training set\n",
      "- Root Mean Squared Error: 3.8359\n",
      "- Mean Absolute Error: 2.5747\n",
      "- R2 Score: 0.9347\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Root Mean Squared Error: 6.2416\n",
      "- Mean Absolute Error: 4.7076\n",
      "- R2 Score: 0.8399\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Retraining the model\n",
    "\n",
    "models = {\n",
    "                \"Ridge Regressor\": Ridge(solver='saga',max_iter=9000,fit_intercept=True, alpha=1),\n",
    "                \"Gradient Boost Regressor\" : GradientBoostingRegressor(n_estimators= 100, random_state=42, min_weight_fraction_leaf=0.01,min_samples_split=13,min_samples_leaf=13,max_depth=13,loss=\"absolute_error\",learning_rate=0.1,criterion=\"friedman_mse\")\n",
    "    }\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "        model = list(models.values())[i]\n",
    "        model.fit(X_train, y_train)  ## Train the model\n",
    "\n",
    "        ##make Predictions\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        ##Evaluate train and test dataset\n",
    "\n",
    "        model_train_mae, model_train_rmse, model_train_r2 = evaluate_model(y_train, y_train_pred)\n",
    "        model_test_mae, model_test_rmse, model_test_r2 = evaluate_model(y_test, y_test_pred)\n",
    "        \n",
    "        print(list(models.keys())[i])\n",
    "\n",
    "        print('Model performance for Training set')\n",
    "        print(\"- Root Mean Squared Error: {:.4f}\".format(model_train_rmse))\n",
    "        print(\"- Mean Absolute Error: {:.4f}\".format(model_train_mae))\n",
    "        print(\"- R2 Score: {:.4f}\".format(model_train_r2))\n",
    "    \n",
    "        print('----------------------------------')\n",
    "        \n",
    "        print('Model performance for Test set')\n",
    "        print(\"- Root Mean Squared Error: {:.4f}\".format(model_test_rmse))\n",
    "        print(\"- Mean Absolute Error: {:.4f}\".format(model_test_mae))\n",
    "        print(\"- R2 Score: {:.4f}\".format(model_test_r2))\n",
    "        \n",
    "        print('='*35)\n",
    "        print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9f23f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Selecting Ridge Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3d8e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f874e278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176d2d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3c1004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6085f378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3be0a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974c88f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468ad407",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
